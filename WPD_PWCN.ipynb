{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. The core logic of the WPD_PWCN model\n",
    "# 1. The input signal is segmented into 1000 data points, corresponding to a temporal resolution of 10â€¯ms, to ensure consistent time scales across all samples.\n",
    "# 2. Each signal is subjected to a three-level wavelet packet decomposition using the db4 wavelet basis, yielding eight sub-bands that capture distinct frequency-domain characteristics.\n",
    "# 3. Each sub-band is convolved with 16 learnable Morlet wavelet kernels, resulting in the extraction of 128 low-level features in the first convolutional layer, which possess explicit physical interpretability.\n",
    "# 4. An attention mechanism is embedded within the first wavelet convolution module to adaptively enhance the feature response of critical frequency components, thereby improving the overall representational capacity.\n",
    "# 5. The extracted features are subsequently fed into a deep convolutional neural network for further high-level feature abstraction and pattern discrimination, enabling accurate classification of signal categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import copy\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "import imageio\n",
    "import time\n",
    "from torchvision import transforms, models, datasets\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import random\n",
    "from torchinfo import summary\n",
    "import os   \n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The location of the dataset\n",
    "root = \"C:\\\\Users\\\\asus\\\\Desktop\\\\JMP4\\\\expdata\\\\db4\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSet(Dataset):\n",
    "\n",
    "    def __init__(self, txts_path1: list, txts_class: list, transform=None):\n",
    "        self.txts_path1 = txts_path1\n",
    "        self.txts_class = txts_class\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.txts_path1)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        txt = scipy.io.loadmat(self.txts_path1[item])\n",
    "        txt = txt['feature']\n",
    "        txt = np.expand_dims(txt, 1)\n",
    "        txt = torch.from_numpy(txt.astype(np.float32))\n",
    "\n",
    "        txt1 = txt[0,:]\n",
    "        txt2 = txt[1,:]\n",
    "        txt3 = txt[2,:]\n",
    "        txt4 = txt[3,:]\n",
    "        txt5 = txt[4,:]\n",
    "        txt6 = txt[5,:]\n",
    "        txt7 = txt[6,:]\n",
    "        txt8 = txt[7,:]\n",
    "        \n",
    "        label = self.txts_class[item]\n",
    "\n",
    "        return txt1,txt2,txt3,txt4,txt5,txt6,txt7,txt8, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "manualSeed = 666 \n",
    "random.seed(manualSeed)\n",
    "\n",
    "# Get the list of category folders\n",
    "item_class = [cla for cla in os.listdir(root) if os.path.isdir(os.path.join(root, cla))]\n",
    "item_class.sort()\n",
    "\n",
    "# Categories are mapped to the index\n",
    "class_indices = dict((k, v) for v, k in enumerate(item_class))\n",
    "\n",
    "all_images_path = []\n",
    "all_images_label = []\n",
    "every_class_num = []\n",
    "\n",
    "for cla in item_class:\n",
    "    cla_path = os.path.join(root, cla)     \n",
    "    images = [os.path.join(cla_path, i) for i in os.listdir(cla_path)]\n",
    "    image_class = class_indices[cla]\n",
    "\n",
    "    all_images_path.extend(images)\n",
    "    all_images_label.extend([image_class] * len(images))\n",
    "    every_class_num.append(len(images))\n",
    "\n",
    "print(\"{} images were found in the dataset.\".format(sum(every_class_num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = MyDataSet(txts_path1=all_images_path, txts_class=all_images_label)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    full_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,  \n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "for step, (txt1,txt2,txt3,txt4,txt5,txt6,txt7,txt8, label) in enumerate(train_loader):\n",
    "    if step > 0:\n",
    "        break\n",
    "sample = txt1[0]\n",
    "print(sample.shape)\n",
    "sample = torch.squeeze(sample,dim=0)\n",
    "\n",
    "sample = sample.numpy()\n",
    "plt.plot(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from math import pi\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Morlet(p):\n",
    "    C = pow(pi, 0.25)\n",
    "    y = C * torch.exp(-torch.pow(p, 2) / 2) * torch.cos(2 * pi * p)\n",
    "    return y\n",
    "\n",
    "class Morlet_fast(nn.Module):\n",
    "\n",
    "    def __init__(self, out_channels, kernel_size, in_channels=1):\n",
    "\n",
    "        super(Morlet_fast, self).__init__()\n",
    "\n",
    "        if in_channels != 1:\n",
    "\n",
    "            msg = \"MexhConv only support one input channel (here, in_channels = {%i})\" % (in_channels)\n",
    "            raise ValueError(msg)\n",
    "\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size - 1\n",
    "\n",
    "        if kernel_size % 2 == 0:\n",
    "            self.kernel_size = self.kernel_size + 1\n",
    "\n",
    "        self.a_ = nn.Parameter(torch.linspace(1, 10, out_channels)).view(-1, 1)\n",
    "\n",
    "        self.b_ = nn.Parameter(torch.linspace(0, 10, out_channels)).view(-1, 1)\n",
    "\n",
    "    def forward(self, waveforms):\n",
    "\n",
    "        time_disc_right = torch.linspace(0, (self.kernel_size / 2) - 1,\n",
    "                                         steps=int((self.kernel_size / 2)))\n",
    "\n",
    "        time_disc_left = torch.linspace(-(self.kernel_size / 2) + 1, -1,\n",
    "                                        steps=int((self.kernel_size / 2)))\n",
    "\n",
    "        p1 = time_disc_right.cuda() - self.b_.cuda() / self.a_.cuda()\n",
    "        p2 = time_disc_left.cuda() - self.b_.cuda() / self.a_.cuda()\n",
    "\n",
    "        Morlet_right = Morlet(p1)\n",
    "        Morlet_left = Morlet(p2)\n",
    "\n",
    "        Morlet_filter = torch.cat([Morlet_left, Morlet_right], dim=1)  # 40x1x250\n",
    "\n",
    "        self.filters = (Morlet_filter).view(self.out_channels, 1, self.kernel_size).cuda()\n",
    "        output = F.conv1d(waveforms, self.filters, stride=1, padding=1, dilation=1, bias=None, groups=1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttention1D(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, ratio=4):\n",
    "        super(ChannelAttention1D, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, in_channels // ratio, 1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(in_channels // ratio, in_channels, 1, bias=False)\n",
    "        )\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        out = self.sigmoid(out)\n",
    "        return out,x,out * x  \n",
    "\n",
    "class SpatialAttention1D(nn.Module):\n",
    "\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention1D, self).__init__()\n",
    "\n",
    "        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'\n",
    "        padding = 3 if kernel_size == 7 else 1\n",
    "        self.conv1 = nn.Conv1d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        out = torch.cat([avg_out, max_out], dim=1)\n",
    "        out = self.sigmoid(self.conv1(out))\n",
    "        return out,x,out * x\n",
    "\n",
    "class CBAM1D(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, ratio=4, kernel_size=3):\n",
    "        super(CBAM1D, self).__init__()\n",
    "        self.channelattention = ChannelAttention1D(in_channels, ratio=ratio)\n",
    "        self.spatialattention = SpatialAttention1D(kernel_size=kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        weight1,x1,out1 = self.channelattention(x)\n",
    "        weight2,x2,out2 = self.spatialattention(out1)\n",
    "        return out2\n",
    "    \n",
    "class WPD_PWCN(nn.Module):\n",
    "    def __init__(self, in_channel=1, out_channel=5):\n",
    "        super(WPD_PWCN, self).__init__()\n",
    "        self.conv1 = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                Morlet_fast(16, 32),\n",
    "                nn.BatchNorm1d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            ),\n",
    "            CBAM1D(in_channels=16)  # ADD CBAM1D \n",
    "        ])\n",
    "        \n",
    "        self.conv2 = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                Morlet_fast(16, 32),\n",
    "                nn.BatchNorm1d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            ),\n",
    "            CBAM1D(in_channels=16)  # ADD CBAM1D\n",
    "        ])\n",
    "        \n",
    "        self.conv3 = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                Morlet_fast(16, 32),\n",
    "                nn.BatchNorm1d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            ),\n",
    "            CBAM1D(in_channels=16)  # ADD CBAM1D\n",
    "        ])\n",
    "        \n",
    "        self.conv4 = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                Morlet_fast(16, 32),\n",
    "                nn.BatchNorm1d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            ),\n",
    "            CBAM1D(in_channels=16)  # ADD CBAM1D\n",
    "        ])\n",
    "                    \n",
    "        self.conv5 = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                Morlet_fast(16, 32),\n",
    "                nn.BatchNorm1d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            ),\n",
    "            CBAM1D(in_channels=16)  # ADD CBAM1D\n",
    "        ])\n",
    "                        \n",
    "        self.conv6 = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                Morlet_fast(16, 32),\n",
    "                nn.BatchNorm1d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            ),\n",
    "            CBAM1D(in_channels=16)  # ADD CBAM1D\n",
    "        ])\n",
    "                            \n",
    "        self.conv7 = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                Morlet_fast(16, 32),\n",
    "                nn.BatchNorm1d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            ),\n",
    "            CBAM1D(in_channels=16)  # ADD CBAM1D\n",
    "        ])\n",
    "                                \n",
    "        self.conv8 = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                Morlet_fast(16, 32),\n",
    "                nn.BatchNorm1d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            ),\n",
    "            CBAM1D(in_channels=16)  # ADD CBAM1D\n",
    "        ])\n",
    "        \n",
    "        self.conv9 = nn.Sequential(\n",
    "            nn.Conv1d(128, 128, 16),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),    \n",
    "            nn.AdaptiveMaxPool1d(25)  # adaptive change the outputsize\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(128 * 25, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2)\n",
    "        )\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2)\n",
    "        )\n",
    "        \n",
    "        self.fc3 = nn.Linear(64, out_channel)\n",
    "\n",
    "    def forward(self, x1, x2, x3, x4, x5, x6, x7, x8):\n",
    "        for module in self.conv1:\n",
    "            x1 = module(x1)\n",
    "        for module in self.conv2:\n",
    "            x2 = module(x2)\n",
    "        for module in self.conv3:\n",
    "            x3 = module(x3)\n",
    "        for module in self.conv4:\n",
    "            x4 = module(x4)\n",
    "        for module in self.conv5:\n",
    "            x5 = module(x5)\n",
    "        for module in self.conv6:\n",
    "            x6 = module(x6)\n",
    "        for module in self.conv7:\n",
    "            x7 = module(x7)\n",
    "        for module in self.conv8:\n",
    "            x8 = module(x8)\n",
    "\n",
    "        x = torch.cat((x1, x2, x3, x4, x5, x6, x7, x8), 1)\n",
    "        x = self.conv9(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WPD_PWCN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using {} device.\".format(device))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, [(1,1,1256),(1,1,1256),(1,1,1256),(1,1,1256),(1,1,1256),(1,1,1256),(1,1,1256),(1,1,1256)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# five-fold cross-validation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear) or isinstance(m, Morlet_fast):\n",
    "        if isinstance(m, Morlet_fast):\n",
    "            nn.init.xavier_uniform_(m.a_)\n",
    "            nn.init.xavier_uniform_(m.b_)\n",
    "        else:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "def train_model(model, train_loader, train_rate, criterion, optimizer, num_epochs, num_folds=5):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    train_loss_all = []\n",
    "    train_acc_all = []\n",
    "    val_loss_all = []\n",
    "    val_acc_all = []\n",
    "    since = time.time()\n",
    "\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(train_loader.dataset), 1):\n",
    "        print(f'Fold {fold}/{num_folds}')\n",
    "        train_dataset = torch.utils.data.Subset(train_loader.dataset, train_index)\n",
    "        val_dataset = torch.utils.data.Subset(train_loader.dataset, val_index)\n",
    "\n",
    "        train_loader_fold = torch.utils.data.DataLoader(train_dataset, batch_size=train_loader.batch_size, shuffle=True)\n",
    "        val_loader_fold = torch.utils.data.DataLoader(val_dataset, batch_size=train_loader.batch_size, shuffle=False)\n",
    "\n",
    "        model.apply(weights_init)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "            print('-' * 10)\n",
    "\n",
    "            # training\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            train_corrects = 0\n",
    "            train_num = 0\n",
    "            for step, (b_x1, b_x2, b_x3, b_x4, b_x5, b_x6, b_x7, b_x8, b_y) in enumerate(train_loader_fold):\n",
    "                b_x1 = b_x1.cuda()\n",
    "                b_x2 = b_x2.cuda()\n",
    "                b_x3 = b_x3.cuda()\n",
    "                b_x4 = b_x4.cuda()\n",
    "                b_x5 = b_x5.cuda()\n",
    "                b_x6 = b_x6.cuda()\n",
    "                b_x7 = b_x7.cuda()\n",
    "                b_x8 = b_x8.cuda()\n",
    "                b_y = b_y.cuda()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output = model(b_x1, b_x2, b_x3, b_x4, b_x5, b_x6, b_x7, b_x8)\n",
    "                loss = criterion(output, b_y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                pre_lab = torch.argmax(output, 1)\n",
    "                train_loss += loss.item() * b_x1.size(0)\n",
    "                train_corrects += torch.sum(pre_lab == b_y.data)\n",
    "                train_num += b_x1.size(0)\n",
    "\n",
    "            train_loss_all.append(train_loss / train_num)\n",
    "            train_acc_all.append(train_corrects.double().item() / train_num)\n",
    "\n",
    "            # val\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_corrects = 0\n",
    "            val_num = 0\n",
    "            with torch.no_grad():\n",
    "                for b_x1, b_x2, b_x3, b_x4, b_x5, b_x6, b_x7, b_x8, b_y in val_loader_fold:\n",
    "                    b_x1 = b_x1.cuda()\n",
    "                    b_x2 = b_x2.cuda()\n",
    "                    b_x3 = b_x3.cuda()\n",
    "                    b_x4 = b_x4.cuda()\n",
    "                    b_x5 = b_x5.cuda()\n",
    "                    b_x6 = b_x6.cuda()\n",
    "                    b_x7 = b_x7.cuda()\n",
    "                    b_x8 = b_x8.cuda()\n",
    "                    b_y = b_y.cuda()\n",
    "\n",
    "                    output = model(b_x1, b_x2, b_x3, b_x4, b_x5, b_x6, b_x7, b_x8)\n",
    "                    loss = criterion(output, b_y)\n",
    "\n",
    "                    pre_lab = torch.argmax(output, 1)\n",
    "                    val_loss += loss.item() * b_x1.size(0)\n",
    "                    val_corrects += torch.sum(pre_lab == b_y.data)\n",
    "                    val_num += b_x1.size(0)\n",
    "\n",
    "                val_loss_all.append(val_loss / val_num)\n",
    "                val_acc_all.append(val_corrects.double().item() / val_num)\n",
    "\n",
    "            print(f'Train Loss: {train_loss_all[-1]:.4f} | Train Acc: {train_acc_all[-1]:.4f}')\n",
    "            print(f'Val Loss: {val_loss_all[-1]:.4f} | Val Acc: {val_acc_all[-1]:.4f}')\n",
    "\n",
    "            if val_acc_all[-1] > best_acc:\n",
    "                best_acc = val_acc_all[-1]\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        # testing\n",
    "        labels_for_test = []\n",
    "        preds_for_test = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for b_x1, b_x2, b_x3, b_x4, b_x5, b_x6, b_x7, b_x8, b_y in val_loader_fold:\n",
    "                b_x1 = b_x1.cuda()\n",
    "                b_x2 = b_x2.cuda()\n",
    "                b_x3 = b_x3.cuda()\n",
    "                b_x4 = b_x4.cuda()\n",
    "                b_x5 = b_x5.cuda()\n",
    "                b_x6 = b_x6.cuda()\n",
    "                b_x7 = b_x7.cuda()\n",
    "                b_x8 = b_x8.cuda()\n",
    "                b_y = b_y.cuda()\n",
    "\n",
    "                output = model(b_x1, b_x2, b_x3, b_x4, b_x5, b_x6, b_x7, b_x8)\n",
    "                pre_lab = torch.argmax(output, 1)\n",
    "                labels_for_test.extend(b_y.cpu().numpy())\n",
    "                preds_for_test.extend(pre_lab.cpu().numpy())\n",
    "\n",
    "        accuracy = accuracy_score(labels_for_test, preds_for_test)\n",
    "        precision = precision_score(labels_for_test, preds_for_test, average='macro')\n",
    "        recall = recall_score(labels_for_test, preds_for_test, average='macro')\n",
    "        f1 = f1_score(labels_for_test, preds_for_test, average='macro')\n",
    "\n",
    "        accuracy_scores.append(accuracy)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        print(f\"Fold {fold} metrics:\")\n",
    "        print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"  Precision: {precision:.4f}\")\n",
    "        print(f\"  Recall: {recall:.4f}\")\n",
    "        print(f\"  F1-score: {f1:.4f}\")\n",
    "\n",
    "        time_use = time.time() - since\n",
    "        print(f'Train and validation complete in {time_use // 60:.0f}m {time_use % 60:.0f}s\\n')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    train_process = pd.DataFrame({\n",
    "        'epoch': range(len(train_loss_all)),\n",
    "        'train_loss_all': train_loss_all,\n",
    "        'val_loss_all': val_loss_all,\n",
    "        'train_acc_all': train_acc_all,\n",
    "        'val_acc_all': val_acc_all\n",
    "    })\n",
    "\n",
    "    print(\"Final Results:\")\n",
    "    print(f\"Accuracy: Mean = {np.mean(accuracy_scores):.4f}, Std = {np.std(accuracy_scores):.4f}\")\n",
    "    print(f\"Precision: Mean = {np.mean(precision_scores):.4f}, Std = {np.std(precision_scores):.4f}\")\n",
    "    print(f\"Recall: Mean = {np.mean(recall_scores):.4f}, Std = {np.std(recall_scores):.4f}\")\n",
    "    print(f\"F1-score: Mean = {np.mean(f1_scores):.4f}, Std = {np.std(f1_scores):.4f}\")\n",
    "\n",
    "    return model, train_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start training the model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model, train_process = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=50,\n",
    "    num_folds=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_process.epoch,train_process.train_loss_all, \"ro-\",label=\"Train Loss\")\n",
    "plt.plot(train_process.epoch,train_process.val_loss_all, \"bs-\",label=\"Val Loss\")\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(train_process.epoch,train_process.train_acc_all, \"ro-\",label=\"Train acc\")\n",
    "plt.plot(train_process.epoch,train_process.val_acc_all, \"bs-\",label=\"Val acc\")\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'WPD_PWCN.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
